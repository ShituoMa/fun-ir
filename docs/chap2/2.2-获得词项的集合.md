# 获得词项集合

## 文档分析和编码转换

从名称上看，倒排索引中的“倒排”二字似乎多余，因为一般提到的索引都是从词项反向映射到文档的。但是，倒排索引已经在信息检索中成为了一个标准术语。

还记得上一节我们怎么构造倒排索引的吗？似乎整个过程并不是那么难理解，但现实情况是很复杂的。比如：

- 文档格式不统一：PDF、word、Excel、PPT、png、jpg、mp4、avi……
- 文档语言不统一：中文、英文、日文、韩文、德文、法文、西班牙文……
- 文档编码不统一：UTF-8、GBK、GB18030……

> 大模型在分析文档的时候，也是要把PDF这些做OCR扫描扫成txt文本或者markdown文本等形式

这时，我们回过头反思一个问题：文档是什么？这个问题并不是那么空洞，需要在设计过程中做出判断。

在做好文档的格式分析、文档语言分析和文档编码分析后，还需要定义好文档的分析粒度。是句？段？篇？还是整个文档？粒度太大，则查询查准率低；粒度太小，则查询召回率低。

## 词项集合的确定

你是否在学大模型的时候频繁听到token这个词？在学自然语言处理的时候又频繁听到lexical？你是否对这几个概念比较迷？所以我们有必要澄清一点概念：

- Word词：文本中用分隔符分开的字符串（在英文中的定义）
- Token词条：文档中出现的词或词项的实例
- Term词项：“规范化”的词语（词形变换、拼写变换），是一组相同类的词
- Type词类：多个词条构成的等价类(equivalence class)集合，通常和词项含义相同

**第一步：词条化**

首先，词条化你认为就是单纯的分词就够了吗？那如果特别长的词，是否要进一步拆分？再说，San Francisco这种词，拆开有什么意义吗？Hacker和hacker是两个词还是一个词？

再者，词条化的过程中，数字你怎么处理？比如2024-10-03，你是按短杠做个拆分还是保留整体？密码学里面加密出来的SHA密钥比如324a3df234cb23e怎么拆？早期的IR系统可能不索引数字
但是数字却常常很有用：比如在Web上查找错误代码(一种处理方法是采用n-gram)

**第二步：词条归一化**

这一下，我们就要把词条化中出现的问题都规避掉。比如，该合并的合并该拆分的拆分，该大小写转换的转换，时态语态不定式过去分词该换的换，单词的多种写法该统一统一。除了前面互换方式(即能够归一化成同一词项的词条之间完全平等，可以互换)之外，还可以使用非对称扩展 (asymmetric expansion)方法，来实现词条到词项的映射。

归一化过程中可能会产生一些语言问题，尤其是Multi-Lingual的语料可能存在一些文化差异，这个我们可以放到NLP里面来讨论讨论。这里主要想探讨一下中文语料。虽然这一部分在自然语言处理教程里面提过，但鉴于部分同学没有自然语言处理基础，我还是简单提一下：

中文语料和英文语料不同。英文可以用空格来分单词，但中文写句子的时候是不带间隔的。那难道按汉字分吗？好像也不太合理，还是按词分好一点。那么，怎么将中文语料按词划分呢？这就是中文分词问题，我在自然语言处理教程的第二章讲序列标注那个地方会讲，但那个地方重点是讨论基于机器学习和深度学习的方法。事实上，不用机器学习的方法很早就有了。

在机器学习方法引入之前，按照是否使用词典划分，可以把分词方法分为基于规则的方法和基于词典的方法。基于规则的方法需要人为预定义一些规则，按照规则判断哪些构成词。而基于词典的方法，典型的就比如正向最大匹配和逆向最大匹配。

（案例、代码）

但这样的分词方法，容易出现两个大问题：

- 未登录词问题(Out of Vocabulary,OOV)：出现词典中没有的词，如：人名、地名、机构名、一些新词等等
- 歧义问题(Ambiguition)：同一句子有多种可能的分词结果

这样的问题可以通过一些机器学习方法（例如HMM、条件随机场等）和一些深度学习方法（比如BiLSTM、BERT等方法来学习上下文语义信息）来改善，但至今，哪怕是大模型时代，有些问题它还是容易存在歧义。

不过，有人指出，中文分词准确度的提高并不一定意味着检索系统效果的提高。

我们可以用个例子展示如何进行中文分词：

（案例）

**第三步：数据清洗**

首先是停用词。有些词可能对于检索系统意义没那么大，比如英文里面的a an the he she I you等，中文里面的“的 地 得 之 乎 者 也”。这样的字词，充分映证了什么叫二八定律。就这些词，词频超过了80%的词汇。所以，可以组织一个停用词表，把这些玩意全部扔出去。

第二步是处理一些写法的不规范。比如，color和colour这两种写法都对，就可以统一。还有一些拼写错误，可以在过程中做矫正。一种解决方法是Soundex方法，基于发音建立词之间的关系(Soundex方法将在第三章介绍)。

第三步就是时态语态这些的统一，把词的过去式、进行时、过去分词、第三人称单数、大小写都给统一掉。把词项还原为词根再索引。不过因为英语里面这些变换大部分都有规律，所以可以制定规则来做这个事。



