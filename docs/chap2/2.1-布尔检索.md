# 布尔检索

## 一个信息检索的例子

这一讲我们开始正儿八经了解信息检索了。上一章我们讲到，信息检索是从大规模非结构化数据（通常是文本）的集合（通常保存在计算机上）中找出满足用户信息需求的资料（通常是文档）的过程。这里面就涉及到几个基本要素：要有文档，并且是非结构化文档，有检索的信息需求，并且将多个文档组织形成语料库。

为什么要是非结构化的文档？因为结构化的文档其实就是表格类数据，表格数据的增删改查我们在数据库系统原理的课上已经学习过，如果大家不熟悉，可以参考datawhale的wonderful-sql项目巩固一下SQL的知识。例如，我在SQL里面写个复合查询：

```sql
SELECT 
    a.CustomerID,
    a.CustomerName,
    SUM(a.TotalSales) AS TotalSales,
    COUNT(b.OrderID) AS NumberOfOrders,
    AVG(b.OrderDate) AS AverageOrderDate,
    RANK() OVER (PARTITION BY a.CustomerID ORDER BY SUM(a.TotalSales) DESC) AS SalesRank
FROM 
    Sales a
JOIN 
    Orders b ON a.OrderID = b.OrderID
WHERE 
    a.TotalSales > (SELECT AVG(TotalSales) FROM Sales)
    AND b.OrderDate BETWEEN '2023-01-01' AND '2023-12-31'
GROUP BY 
    a.CustomerID,
    a.CustomerName
HAVING 
    SUM(a.TotalSales) > 10000
ORDER BY 
    TotalSales DESC;
```

但是这样的查询针对文本这种半结构或非结构化内容就比较复杂了。你可能涉及到字符串匹配，在复杂条件查询的时候还可能涉及到与或非的操作，并且现在的检索系统要尽可能实时尽可能快，这对现阶段的检索提出了不小的挑战。

> 之所以文本数据中存在半结构化数据，就是比如html网页这种有一定层级逻辑但是又不完全有的这种。甚至文本本身其实真要分析结构也可以分析，大家可以参考自然语言处理教程里面的依存句法分析、语义角色标注等内容。但是更多的多媒体信息比如图像、视频、音频等那就真没有结构了。

信息检索领域有个著名的案例就是《莎士比亚全集》。不到100万单词，假设每个英文单词平均长度为8字节，则整个全集不到10MB。现在，我需要你帮我检索：莎士比亚的哪部剧本包含Brutus及Caesar但是不包含Calpurnia？我们可以写一个逻辑表达：

```sql
Brutus AND Caesar AND (NOT Calpurnia)
```

一个暴力方法是：从头到尾扫描所有剧本，对每部剧本判断它是否包含Brutus AND Caesar ，同时又不包含Calpurnia。前者可以在扫描到以后退出，但后者带NOT的语句则必须要把文档遍历完才能判断。这会非常耗费时间。有没有更高效一些的方法？

这样吧，我们把每个词汇在《莎士比亚全集》里面出现的情况用一个0-1矩阵表示起来。由于莎士比亚的小说很多，文字也很多，这当然是个稀疏矩阵，按数据结构课上讲的，你可以使用压缩存储的方式保存。

![1735572618030](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735572618030.png)

关联矩阵的每一列(对应一篇文档)都是 0/1向量，每个0/1都对应一个词项。关联矩阵的每一行(对应一个词项)也可以看成一个0/1向量，每个0/1代表该词项在相应文档中的出现与否。那么，我们的每个单词其实都是一个稀疏的01向量，复杂查询语句本质上也就是针对一组向量的位运算。例如，针对上面的例子，计算过程就形如：

```sql
110100 AND 110111 AND (NOT 010000) = 100100
```

如图，一个典型的搜索过程如下所示：

![1735572962526](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735572962526.png)

一个搜索过程的评价可以用这样一些指标描述：

- 查准率：返回结果文档中正确的比例。如返回80篇文档，其中20篇相关，正确率1/4
- 查全率：全部相关文档中被返回的比例，如返回80篇文档，其中20篇相关，但是总的应该相关的文档是100篇，召回率1/5
- F1数值

这样的布尔检索的方式固然好，但再往上走恐怕就很大了。例如，如果文件夹下有10000个文档，每个文档有10000个词，那么词的数量可能是千万级甚至亿级（这是最坏的情况）的，这个矩阵会惊人的大。我们必须找一个更好的办法表示向量。

## 倒排索引

下图是一个信息检索系统应有的架构：

![1735573153432](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735573153432.png)

![1735573167460](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735573167460.png)

好了，言归正传，那话又说回来了。我们想找一种比01矩阵更好的表示方法，那我们就不能盯着01来看。如果我们对每个文档编号，每个词在哪些文档中出现，是否可以用编号的方法标记呢？那如果我们用了编号，并且我把每个词在哪些文档中出现的向量固定一个大小，可不可以？

![1735573396384](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735573396384.png)

这是个线性结构。

一个倒排索引表构建的流程如图所示：

![1735573462775](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735573462775.png)

- 首先，第一步：给每个文档做好分词，统计每个文档里面出现了哪些词
- 然后对这些词排序，可以根据词频来，也可以根据字典排序法等
- 某个词项在单篇文档中的多次出现会被合并
- 拆分成词典和倒排记录表两部分，每个词项出现的文档数目(doc.  frequency, DF)会被加入

![1735573654711](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735573654711.png)

## 布尔查询的处理

那我们把倒排索引构造好了以后，怎么进一步处理呢？

我们以一个简单的例子：Brutus AND Caesar为例。因为本身每个词的文档倒排索引是个线性结构，在硬盘中可以用数组表示，在内存中可以用链表表示。但不管怎么说，这就是两个线性表求交集的问题。我们以链表为例讲述这个过程：

![1735573862465](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735573862465.png)

核心逻辑就是找到这两个单链表有哪些节点是重合的，像极了前几年那个找公共子串的考研408数据结构大题，你发现了没？

这个问题在数据结构刷题营的项目中也有类似的中档题讲述过，本质上就是用双指针。每个倒排记录表都有一个定位指针，两个指针同时从前往后扫描, 每次比较当前指针对应倒排记录，然后移动某个或两个指针。合并时间为两个表长之和的线性时间。如果计算这个过程的时间复杂度，最优不过$O(m+n)$

举一反三，那如果我有三个条件，这不就变成一个三个链表查询？如果我有N个条件，这不就是个N个链表进行查询？那链表多起来了，怎么优化呢？按照表从小到大(即df从小到大)的顺序进行处理。

当然，由于这个思想很朴素，布尔检索被广泛应用于检索系统当中。但它也有很多缺点，比如：

- 布尔查询表达式构建比较复杂，我们平常查百度的那种查询方式在这玩意面前根本行不通
- 布尔检索没有充分利用到词频统计的信息
- 不能对检索结果进行排序，难以获得我们最相关的结果