# 索引构建（下）

## 动态索引构建方法

到目前为止，我们认为文档都是静态的。这对于图书馆可能没什么大毛病，但实际业务场景中这样的假设很难一直成立。例如，新闻数据库是随时更新的。这也意味着词典和倒排记录表必须要动态更新。

一个很纯粹的动态索引思想是使用“主索引+辅助索引”的模式。在磁盘上维护一个大的主索引(Main index)，新文档放入内存中较小的辅助索引中，同时搜索两个索引，然后合并结果，定期将辅助索引合并到主索引中。如果要删除，采用无效位向量(Invalidation bit-vector)来表示删除的文档，利用该维向量过滤返回的结果，以去掉已删除文档。

但这样的做法有个典型的问题：合并过于频繁。合并时如果正好在搜索，那么搜索的性能将很低。实际上，如果每个倒排记录表(对应一个词项)都采用一个单独的文件来存储的话，那么将辅助索引合并到主索引的代价并没有那么高，此时合并等同于一个简单的添加操作。但是这样做将需要大量的文件，效率显然不高。

> 现实当中常常介于上述两者之间(例如：将大的倒排记录表分割成多个独立的文件，将多个小倒排记录表存放在一个文件当中……)

![1735631147417](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735631147417.png)

假设Disk 中已经有了对于文档 (Document) 1 ~ 1000 的索引，将其记作 I 。现在又更新了一批新的文档 1001 ~ 1010，将这一批文档都读入内存 (Memory) 中，得到这一批新文档的索引 I0 ，当内存满了之后，将其与 Disk 中的 I 进行合并。简单的来说，已有 I，每次会得到新的 I0，将 I0 与 I 合并，得到 I’ = I(Doc 1 ~ Doc 1010)。
该策略可以保证，在完成更新环节之后，永远只会有 1 个完整的倒排索引 (Inverted Index)。这就意味着在进行检索的时候，我们也只需在这一个索引中进行操作，如果我们的 Query 的尺寸为 |Q|，那么我们在该索引中进行随机访问的次数也就只有 |Q|，即 I/O 开销为 |Q|

考虑最简单的情况：

- 假设一开始，I = Ø。更新第一批新文档，然后构建它们的索引，|I0| = M，这里不需要合并 (Merge)。
- 更新第二批新文档，同样构建索引，得到 |I0’| = M，现在 Merge(I0, I0’)，得到 I1 = 2 * M。
- 更新第三批文档，得到 |I0’’| = M， Merge(I1, I0’’)，得到 I2 = 3 M。因为每次合并的时候，需要先读取两个 Index，再将合并后的 Index 写回 Disk，因此代价是 2 * Size of Indexes。
  比如第二批时，合并的代价就为 2 * 2M。
- 那么，第 k 批文档更新成功后，得到的最后的索引应为 Ik = k * M，合并代价为 2 * kM。而第一批文档更新时，没有进行任何合并，只是简单地把索引写入 Disk，因此代价只有 M。

![1735631273907](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735631273907.png)

该策略实际将每个词项 (Term) 的倒排记录表 (Posting List) 都单独存成一个文件 (File) ，那么要合并主索引 (Main Index) 和辅助索引 (Auxiliary Indexes) 时，只需要将辅助索引的倒排记录表扩展到主索引对应的倒排记录表即可完成，也就是简单的 append。但这样就需要很多的文件 (File) ，如此一来 I/O 开销就会比较大，合并 (Merge) 的效率就不会很高。还有另外一种比较极端的策略。那就是不合并 (No Merge)。

![1735631292042](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735631292042.png)

假设在 Disk 中已经有了对于文档 (Document) 1 ~ 1000 的索引，将其记作 I 。现在又更新了一批新的文档 1001 ~ 1010，将这一批文档都读入内存 (Memory) 中，得到这一批新文档的索引 I0 ，当内存满了之后，我们 不进行合并 ，直接将 I0 作为一个单独的索引存入 Disk。当下一次，又更新了一批新文档 1011 ~ 1020 时，进行同样的操作。

新的文档集 (Collection) 的尺寸为内存的数倍，即 |C| = k * M ，那么此时就会有 k 个索引，每个索引的尺寸为 M。这样一来进行查询时，对于每一个查询中的词项 (Term)，就需要查找 k 个索引，整体的开销就为 k * |Q|。可以看到，不合并 (No Merge) 策略相比即时合并 (Immediate Merge) 策略，它在查询 (Query) 时的表现会比较差，但是它没有合并操作，因此，没有额外的索引构建开销。

在以上两种策略之间，我们希望能取得一个平衡。这就诞生了对数合并（Logarithmic Merge）。对数合并算法能够缓解(随时间增长)索引合并的开销，用户并不感觉到响应时间上有明显延迟。

- 维护一系列索引，其中每个索引是前一个索引的两倍大小
- 将最小的索引 (Z0) 置于内存
- 其他更大的索引  (I0, I1, . . . ) 置于磁盘
- 如果 Z0 变得太大 (> n), 则将它作为 I0 写到磁盘中(如果 I0 不存在)
- 或者和 I0 合并(如果 I0 已经存在) ，并将合并结果作为I1写到磁盘中(如果 I1 不存在) ，或者和I1合并(如果 I1 已经存在)，依此类推……

更细致地，有对数合并过程：

- 假设一开始，I = Ø。
- 更新第一批新文档，然后构建它们的索引，|I0| = M = 20 * M，满足条件 1 和条件 2
- 更新第二批新文档，同样在内存 (Memory) 构建索引，得到 |I0| = M。这个时候，在 Disk 之中已经有了一个I0 ，这违反了条件 2。
- 因此， Merge(I0, I0)，得到 I1 = 2 * M。
- 更新第三批文档，得到 |I0| = M，这个时候，我们有 I1 和 I0 ，满足条件 1 和条件 2，不需要进行合并
- 更新第四批文档，得到 |I0| = M。此时在 Disk 已有 [I1, I0] ，不符合条件。因此，Merge(I0, I0) = I1，此时仍有 2 个 I1，继续合并 Merge(I1, I1) = I2 = 4 * M = 22 * M，满足条件 1 和条件 2。最后 Disk 中仅有 I2

依旧假设 |C| = k * M 且这里的 k = 2h 。那么，在最后的第 k 批文档处理结束后，能得到一个索引 Ilog(k) = k * M，而在这个索引当中的所有 Entry，都经过了 h = log(k) 次合并。所以，该策略下，构建整个索引的代价为 O(k * M * log(k))。
而对于查询 (Query) 来说，可以考虑最极限的情况，通过条件 2 能够知道，不会有两个 Ik，因此，最多只能同时有 I0, I1, I2, …, Ilog(k) 个索引，即 O(log(k))。因此，查询的最高复杂度为 
O(|Q| * log(k))

![1735631437640](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735631437640.png)

索引数目的上界为 O(log T) (T 是所有倒排记录的个数)，因此，查询处理时需要合并O(log T)个索引，索引构建时间为 O(T log T)。这是因为每个倒排记录需要合并O(log T)次
辅助索引方式： 索引构建时间为O(T2)，因为每次合并都需要处理每个倒排记录。假定每个辅助索引的大小为 a，因此，对数合并的复杂度比辅助索引方式要低一个数量级。

![1735631512646](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735631512646.png)

## 复杂网络与索引构建

这一部分的内容会和我的复杂网络教程有一定关联。主要是利用到了复杂网络中的小世界效应。

基于图的索引其核心思想是：向量空间中的数据点形成一个图，其中节点表示数据值，连接节点的边表示数据点之间的相似性。图的构造方式使得相似的数据点更有可能通过边连接，而 ANN（Approximate Nearest Neighbors） 搜索算法旨在以高效的方式遍历图。基于图的索引的主要优势在于，它们能够在高维数据中找到近似的最近邻，同时还能节省内存，从而提高性能。

HNSW是一种用于在高维空间中进行高效人工神经网络搜索的数据结构和算法。它是跳表和小世界图（SWG）结构的扩展，可以有效地找到近似的最近邻。

![1735631684520](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735631684520.png)

> 小世界（small world）网络是一种特殊的网络，在这种网络中，你可以快速地联系到网络中的其他人或点。说白了，最著名的六度空间理论通俗来说就是：你和一个陌生人要想建立联系不超过六个人。你朋友的朋友没准你也认识。这一部分可以参考我和Prof.Jerry He后续发布的复杂网络教程会讲的更多。

HNSW在层次结构中的基础层之上构造附加层。每个层将有更少的顶点和边的数量。可以把高层中的顶点看作是跳跃列表中访问“高速公路”的点：

<img src="C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735631793857.png" alt="1735631793857" style="zoom:70%;" />

查找过程：

- 搜索从最顶层开始,选择一个随机起点
- 在当前层进行贪婪搜索,不断移动到离目标更近的邻居选择最临近的一些友点，存在定长动态列表中，同时存入废弃表中
- 在第N次查找时，计算动态列表中所有点的友点距离待查找点的距离
- 当在当前层无法找到更近的点时,下降到下一层继续搜索
- 在废弃列表中记录过的不计算，更新废弃列表
- 动态列表重排序，保留前K个
- 前K个点和更新前是否一样，不一样就继续查找，一样则停止，返回前M个结果

- 重复这个过程直到达到底层,得到最终结果

插入新向量过程：

- 确定新向量应该出现在哪些层。
- 从顶层开始,在每一层执行类似于搜索的过程,找到适合连接的邻居点。
- 建立连接,同时可能需要删除一些现有连接以维持图的结构特性。





