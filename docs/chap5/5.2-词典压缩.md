# 词典和索引记录表的压缩

## 词典压缩

一般而言，相对于倒排记录表，词典所占空间较小，为什么还要对词典进行压缩呢？
决定信息检索系统查询响应时间的一个重要因素是磁盘的访问次数，词典部分在磁盘上就需要更多的磁盘访问次数。因此，词典压缩的主要目的是将词典放入内存。另外，满足一些特定领域特定应用的需要，如手机、机载计算机上的应用或要求快速启动等需求。因此，压缩词典相当重要。

但定长方式也有一些不足，很多的词条把空间浪费了，有些词条又不够用。

如果我们把整个词典都看作一个字符串呢？将所有词项存成一个长字符串，并给每个词项增加一个定位指针。

![1735633667203](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735633667203.png)

- 每个词项的文档频率需要4个字节
- 每个词项指向倒排记录表的指针需要4个字节
- 每个词项平均需要8个字节
- 指向字符串的指针需要3个字节 (8*400000个位置需要log2（8 * 400000） < 24 位来表示)
- 空间消耗: 400,000 × (4 +4 +3 + 8) = 7.6MB  (而定长数组方式需要11.2MB)
- 压缩了大概1/3

进一步压缩，将长字符串中的词项进行分组，变成大小为k的块，然后对每个块只保留第一个词项的指针，用一个额外字节将每个词项的长度存储在每个词项的首部。

![1735633724937](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735633724937.png)

如果不按块存储，则每4个词项指针将占据空间4 × 3=12B。现在按块存储，假设块大小k=4，此时每4个词项只需要保留1个词项指针，但是同时需要增加4个字节来表示每个词项的长度，此时每4个词项需要3+4=7B。因此，每4个词项将节省12-7=5B，于是，整个词典空间将节省40,000/4*5B=0.5MB，最终的词典空间将从7.6MB压缩至7.1MB

显然，k越大压缩率越高，但是，压缩和查询之间需要达到平衡

- **前端编码**：当前，词项之间的冗余信息还没用使用。按照词典顺序排序的连续词项之间具有公共前缀。采用前端编码技术，后续的词项用特殊字符表示该前缀
- **最小完美哈希**：其他具有高压缩率的方法依赖于最小完美哈希。该哈希函数将M个词项映射到[1……M]上，并且不发生冲突。但是，当插入新词项时显然会发生冲突，此时不能对原有的完美哈希结构进行增量修改，需重新构造新的完美哈希函数。因此，完美哈希的方法无法在动态环境下使用。

## 倒排记录表压缩

倒排记录表空间远大于词典，至少10倍以上。压缩的关键在于对每条倒排记录进行压缩。目前每条倒排记录表中存放的是docID。对于Reuters RCV1(800,000篇文档), 当每个docID可以采用4字节（即32位）整数来表示。当然，我们也可以采用log2 800,000 ≈ 19.6 < 20 位来表示每个docID。我们的压缩目标是： 压缩后每个docID用到的位数远小于20比特

**关键思想: 存储docID间隔而不是docID本身**

每个倒排记录表中的docID是从低到高排序，存储间隔能够降低开销。于是可以顺序存储间隔(第一个不是间隔) 。高频词项的间隔较小，因此，可以对这些间隔采用小于20比特的存储方式。

![1735634019608](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735634019608.png)

存在的问题？

- 间隔的最大值取决于索引的网页总数
- 不频繁词项的间隔较少/值较大
- 频繁词项的间隔较多/值较小

因此，我们换一个想法：对间隔用变长编码。

- 对于 arachnocentric 及其他罕见词项, 对每个间隔仍然使用20比特
- 对于the及其他高频词项，每个间隔仅仅使用很少的比特位来编码

可变长编码对于小间隔采用短编码而对于长间隔采用长编码。VB编码利用整数个字节来对间距编码，字节的后7位是间距的有效编码区，而第1位是延续位。如果该位为1，则表明本字节是某个间距编码的最后一个字节，否则不是。解码时，可以读入一段字节序列，其中前面的字节的延续位都是0，而最后一个字节的延续位为1，根据上述规则，把每个字节的7位部分抽取出来并连接在一起形成编码

![1735634225914](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735634225914.png)

**解码**

![1735634242329](C:\Users\马世拓\AppData\Roaming\Typora\typora-user-images\1735634242329.png)

除字节外，还可以采用不同的对齐单位：比如32位(word)、16位及4位(nibble，半字节)等等。如果有很多很小的间隔，那么采用可变字节码会浪费很多空间，而此时采用4位为单位将会节省空间。以字节为单位在压缩率和解压缩的速度之间提供了一个很好的平衡点。

VB编码能够根据间距的大小采用合适的字节数来编码，而基于位的编码能够在更细的位粒度上进行编码长度的自适应调整。最简单的位编码是一元码(unary code)。一元码就是将 n 表示成 n 个1后加一个0组成的字符串。

γ编码是一种用于压缩整数序列的高效编码方法，特别适用于倒排索引中的文档ID序列。其基本思想是将整数分解为两部分：长度部分和值部分。

**基本过程**：
1. **长度部分**：
   - 将整数 \( n \) 的二进制表示中的最高位1之前的0的数量（包括最高位的1）编码为一串1后跟一个0。例如，对于整数8（二进制为1000），其长度部分为110.
2. **值部分**：
   - 将整数 \( n \) 的二进制表示中除去最高位1之后的部分直接编码。对于整数8，其值部分为000.
3. **合并**：
   - 将长度部分和值部分合并，形成最终的γ编码。对于整数8，其γ编码为110000.

**优点**：
- **高效压缩**：γ编码能够有效地压缩整数序列，特别是当整数较小或序列中的整数差异较小时，压缩效果显著。
- **简单实现**：γ编码的编码和解码过程相对简单，易于实现。
- **适用广泛**：适用于多种需要压缩整数序列的场景，如倒排索引中的文档ID序列。

**缺点**：
- **压缩率限制**：对于较大的整数，γ编码的压缩率可能不如其他更复杂的编码方法。
- **解码速度**：虽然编码和解码过程简单，但在某些情况下，解码速度可能不如其他优化过的编码方法。

总体而言，γ编码在倒排索引压缩中是一种有效的工具，能够在保持较高压缩率的同时，提供相对简单的实现和较快的解码速度.

现在，让我们回到这一章的开始。压缩以后的倒排索引有多大？如果平均的doc-id长度为6位，那么，倒排表只需要1.5TB。如果压缩后的倒排索引表要做趟索引，需要多长时间？7.58秒，这就好很多了。还能继续优化吗？

假设对倒排表的doc-id进行重新排序，使得最相关的文档id排在前面，对应查询retrieval可快速返回前十个相关文档：从倒排记录表中读取前10个doc-id后即可提前结束。但是这个方法不能支持倒排表压缩、倒排记录表的合并。

对所有文档定义一个静态（或全局的）打分（如Google PageRank），按PageRank升序，对doc-id进行重新编号。对应每个词项，PageRank值高的文档将出现在倒排记录表的前面部分。在此我们估算查询词项的选择率，仅处理部分倒排记录表。此时，我们只需要处理千分之几甚至万分之几的倒排记录，时间也从秒级降到毫秒级。



