# 信息检索中的概率论基础

## 1. 概率论基础  
**1.1 概率的定义与基本概念**  
在信息检索中，概率用于量化不确定性。例如，用户在搜索时输入的查询词可能与多个文档相关，但相关程度不同，需用概率衡量。  
- **样本空间（Ω）**：所有可能结果的集合（如文档集合中的每一篇文档）。  
- **事件（A）**：样本空间的子集（如“文档包含关键词‘人工智能’”）。  
- **概率公理**：  
  - 非负性：$ P(A) \geq 0 $  
  - 规范性：$ P(\Omega) = 1 $  
  - 可加性：若事件互斥，$ P(A \cup B) = P(A) + P(B) $。  

**1.2 条件概率与独立性**  
- **条件概率**：在已知事件B发生的条件下，事件A的概率为：  
  $$
  P(A|B) = \frac{P(A \cap B)}{P(B)} \quad (P(B) > 0)
  $$  
  例如，已知文档包含“机器学习”，其同时包含“深度学习”的概率。  
- **独立性**：若$ P(A \cap B) = P(A)P(B) $，则A与B独立。在布尔模型中，假设词项独立出现（朴素贝叶斯假设）。  

---

## 2. 贝叶斯统计与信息检索  
**2.1 贝叶斯定理**  
贝叶斯定理是信息检索中概率模型的核心工具：  
$$
P(H|E) = \frac{P(E|H)P(H)}{P(E)}
$$  
- **应用场景**：  
  - **垃圾邮件过滤**：假设H为“邮件是垃圾邮件”，E为“邮件包含‘免费’一词”，计算后验概率$ P(H|E) $。  
  - **文档相关性排序**：给定查询Q，文档D的相关性概率$ P(R=1|D,Q) $。  

**2.2 朴素贝叶斯分类器**  
假设特征（如词项）条件独立：  
$$
P(C|d) \propto P(C) \prod_{w \in d} P(w|C)
$$  
其中，C为类别（如相关/不相关），d为文档。  
- **局限性**：词项独立性假设在实际中可能不成立（如“人工智能”与“机器学习”相关）。  

---

## 3. 排列组合在信息检索中的应用  
**3.1 组合分析**  
- **查询扩展**：从n个候选词中选择k个加入查询，共有$ \binom{n}{k} $种组合方式。  
- **倒排索引优化**：若文档包含m个词项，其可能的词项组合数为$ 2^m - 1 $（非空子集）。  

**3.2 排列与排序**  
- **检索结果排序**：若对n篇文档按相关性排序，可能的排列数为$ n! $。实际系统中需高效计算Top-K（如PageRank的马尔可夫链收敛）。  
- **n-gram模型**：词序列$ w_1w_2...w_n $的概率计算依赖排列组合（如二元语法模型$ P(w_i|w_{i-1}) $）。  
