# 检索系统的初步评测指标

## 为什么要评价

### 为什么要对检索系统进行评价
- **提高系统性能**：通过评价可以发现检索系统在处理不同查询时的优缺点，从而针对性地进行优化和改进。
- **比较不同系统或算法**：评价可以帮助我们比较不同检索系统或算法的性能，选择最适合特定应用场景的系统。
- **推动研究发展**：通过评价可以验证新算法和新技术的有效性，推动信息检索领域的研究不断进步。
- **满足用户需求**：评价可以确保检索系统能够更好地满足用户的实际信息需求，提高用户满意度。

### 如何评价检索系统
- **构建测试集**：建立一个包含文档集、信息需求集合和相关性判定结果的测试集。
- **选择评价指标**：常用的评价指标包括查准率（Precision）、查全率（Recall）、F1值（F1 Score）、平均准确率（Mean Average Precision, MAP）等。
- **计算指标值**：根据测试集中的数据，计算每个评价指标的值，以量化检索系统的性能。
- **分析结果**：对计算得到的指标值进行分析，找出系统的优势和不足，为后续改进提供依据。

### 主观评价与客观评价
- **主观评价**：
  - **定义**：主观评价依赖于用户或专家的主观判断，评价结果可能因个人偏好、经验和认知差异而有所不同。
  - **方法**：通过用户调查、问卷调查等方式，收集用户对检索结果的满意度、相关性等主观感受。
  - **优点**：能够直接反映用户的真实需求和体验，有助于理解用户对检索系统的整体感受。
  - **缺点**：评价结果可能不够稳定和一致，受主观因素影响较大。

- **客观评价**：
  - **定义**：客观评价基于预先定义的评价指标和标准，通过计算和分析得到的评价结果。
  - **方法**：使用查准率、查全率等客观指标，根据测试集中的数据进行计算。
  - **优点**：评价结果具有较高的稳定性和可重复性，能够客观地反映检索系统的性能。
  - **缺点**：可能无法完全涵盖用户的所有需求和体验，有时需要结合主观评价来全面评估。

在实际应用中，通常结合主观评价和客观评价，以获得更全面、准确的评价结果，从而更好地优化和改进检索系统。

那么，在检索系统中我们评价什么呢？

- 效率 (Efficiency)—可以采用通常的评价方法
  - 时间开销
  - 空间开销
  - 响应速度
- 效果 (Effectiveness)
  - 返回的文档中有多少相关文档
  - 所有相关文档中返回了多少
  - 返回得靠不靠前
- 其他指标
  - 覆盖率(Coverage)（后面介绍）
  - 访问量
  - 数据更新速度

那怎么比较这些要素呢？这本教材我就不想像讲计算机视觉和自然语言处理以及网络安全一样搞得太学术化，想尽量偏基础性一些，所以我尽可能少地用一些学术性的词汇。但是大家以前学习的时候肯定知道一个东西叫控制变量。评测检索系统时我们也要控制变量。相同的文档集合，相同的查询主题集合，相同的评价指标，不同的检索系统进行比较。

## 有哪些常见评价指标

### 查准率（Precision）
- **公式**：
  $$
  \text{Precision} = \frac{TP}{TP + FP}
  $$
- **变量意义**：
  - $TP $：真正例（True Positive），即正确识别为正类的样本数。
  - $FP $：假正例（False Positive），即错误识别为正类的样本数。

### 召回率（Recall）
- **公式**：
  $$
  \text{Recall} = \frac{TP}{TP + FN}
  $$
- **变量意义**：
  - $TP $：真正例（True Positive），即正确识别为正类的样本数。
  - $FN $：假负例（False Negative），即错误识别为负类的正类样本数。

### 混淆矩阵（Confusion Matrix）
- **公式**：
  $$
  \begin{array}{c|cc}
    & \text{预测正类} & \text{预测负类} \\
    \hline
    \text{实际正类} & TP & FN \\
    \text{实际负类} & FP & TN \\
  \end{array}
  $$
- **变量意义**：
  - $TP $：真正例（True Positive），即正确识别为正类的样本数。
  - $FN $：假负例（False Negative），即错误识别为负类的正类样本数。
  - $FP $：假正例（False Positive），即错误识别为正类的样本数。
  - $TN $：真负例（True Negative），即正确识别为负类的样本数。

### F1值（F1 Score）
- **公式**：
  $$
  F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
  $$
- **变量意义**：
  - $\text{Precision} $：查准率。
  - $\text{Recall} $：召回率。

### AUC（Area Under the Curve）
- **公式**：
  $$
  \text{AUC} = \int_{0}^{1} \text{Recall}(FPR) \, dFPR
  $$
- **变量意义**：
  - $\text{Recall} $：召回率。
  - $FPR $：假正率（False Positive Rate），即 $FPR = \frac{FP}{FP + TN} $。

### P-R曲线（Precision-Recall Curve）
- **公式**：
  $$
  \text{P-R曲线} = \{ (\text{Recall}(T), \text{Precision}(T)) \mid T \in \text{所有可能的阈值} \}
  $$
- **变量意义**：
  - $\text{Recall}(T) $：在阈值 $T $ 下的召回率。
  - $\text{Precision}(T) $：在阈值 $T $ 下的查准率。

### 准确率（Accuracy）
- **公式**：
  $$
  \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
  $$
- **变量意义**：
  - $TP $：真正例（True Positive），即正确识别为正类的样本数。
  - $TN $：真负例（True Negative），即正确识别为负类的样本数。
  - $FP $：假正例（False Positive），即错误识别为正类的样本数。
  - $FN $：假负例（False Negative），即错误识别为负类的正类样本数。

对于大规模语料集合，列举每个查询的所有相关文档是不可能的事情，因此，这种情况几乎不可能准确地计算召回率

**缓冲池(Pooling)方法**：对多个检索系统的Top k个结果组成的集合(并集)进行人工标注，标注出的相关文档集合作为整个相关文档集合。这种做法被验证是可行的(可以比较不同系统的相对效果)，在TREC会议中被广泛采用。

**平均正确率(Average Precision, AP)**：对不同召回率点上的正确率进行平均

- 未插值的AP(常用): 某个查询Q共有6个相关结果，某系统排序返回了5篇相关文档，其位置分别是第1，第2，第5，第10，第20位，则AP=(1/1+2/2+3/5+4/10+5/20+0)/6
- 插值的AP:在召回率分别为0,0.1,0.2,…,1.0的十一个点上的正确率求平均，等价于11点平均
- 只对返回的相关文档进行计算的AP AP=(1/1+2/2+3/5+4/10+5/20)/5，倾向那些快速返回结果的系统

**Precision@N**：在第N个位置上的正确率，对于搜索引擎，大量统计数据表明，大部分搜索引擎用户只关注前一、两页的结果，因此，P@10, P@20对大规模搜索引擎来说是很好的评价指标

**mAP**: $mAP=AP(Q1)+AP(Q2)+…+AP(Qn)/n$

## 更多评价

- 相关性试图度量用户的满意程度，但是用户是否满意取决于很多因素。
- 用户工作量：用户是否容易构建查询、进行搜索以及浏览返回结果
- 响应时间：输入到输入之间的等待时间
- 结果呈现方式：用户方便浏览获得答案
- 文档集覆盖度：文档集对相关文档的覆盖程度

搜索引擎往往还会考虑多样性(diversity)：结果的多样性，比如输入“苹果”，可以是公司、产品、操作系统、水果等等。



前面的指标都没有考虑用户因素。而相关不相关由用户判定。在信息检索系统中，评价检索效果的核心指标包括**覆盖率**、**新率**以及**平均倒数排名（MRR）**。这些指标从不同角度衡量检索系统的性能，适用于不同的应用场景。


覆盖率用于衡量检索系统找到用户已知相关文档的能力。假设用户已知的相关文档集合为 $U$，检索结果与 $U$ 的交集为 $R_u$，则覆盖率 $C$ 定义为：  
$$
C = \frac{|R_u|}{|U|}
$$  
其中，$|R_u|$ 表示检索结果中用户已知的相关文档数量，$|U|$ 表示用户已知的相关文档总数。覆盖率越高，说明系统找到的用户已知相关文档比例越大。

新率用于衡量检索系统返回用户未知相关文档的能力。假设检索结果中返回了一些用户以前未知的相关文档 $R_k$，则新率 $N$ 定义为：  
$$
N = \frac{|R_k|}{|R_u| + |R_k|}
$$  
其中，$|R_k|$ 表示检索结果中用户未知的相关文档数量，$|R_u|$ 表示检索结果中用户已知的相关文档数量。新率越高，说明系统返回的新相关文档比例越大。


MRR 是一种适用于问答系统或主页发现系统的评价指标，重点关注第一个标准答案返回的位置（Rank）。对于每个查询，系统返回的第一个正确答案的排名倒数称为**倒数排名（Reciprocal Rank, RR）**。对多个查询的 RR 求平均，即得到 MRR：  
$$
\text{MRR} = \frac{1}{n} \sum_{i=1}^n \frac{1}{\text{Rank}_i}
$$  
其中，$n$ 表示查询总数，$\text{Rank}_i$ 表示第 $i$ 个查询的第一个正确答案的排名。MRR 越高，说明系统返回正确答案的位置越靠前。

**示例**：  
假设系统对两个查询的返回结果如下：  
- 第一个查询的第一个正确答案排名为 2，其 RR 为 $\frac{1}{2}$。  
- 第二个查询的第一个正确答案排名为 4，其 RR 为 $\frac{1}{4}$。  
则系统的 MRR 为：  
$$
\text{MRR} = \frac{\frac{1}{2} + \frac{1}{4}}{2} = \frac{3}{8}
$$



只有在用户的评定一致时，相关性判定的结果才可用。如果结果不一致，那么不存在标准答案，无法重现实验结果。如何度量不同判定人之间的一致性？


Kappa 指标是一种用于度量判定间一致性的统计量，广泛应用于需要比较两次数据或两种方法之间一致性的场景。例如，评估两位医生的诊断结果是否一致，或两位裁判的评分标准是否一致等。该指标专为类别型判断结果设计，旨在对分类问题进行更深入的理解。通过修正正确率，Kappa 指标排除了仅靠偶然性（或随机性）获得正确分类的因素，从而提供了一个更为准确的一致性度量。

Kappa 系数的计算公式为：
$$
\kappa = 1 - \frac{1-P(E)}{P(A)-P(E)}
$$

其中：
P(A) 表示评价者之间观察到的一致性概率，即实际判定结果中一致的比例。
P(E) 表示评价者之间偶然一致性的概率，即在随机情况下判定结果一致的期望比例。

Kappa 系数的取值范围在 0 到 1 之间：
- κ=0：表示完全不一致，即评价者之间的判定结果没有任何一致性。
- κ=1：表示完全一致，即评价者之间的判定结果完全一致。
- 中间值：表示不同程度的一致性，其中 κ 在 [2/3,1.0] 之间时，判定结果通常被认为是可接受的。如果 κ 值较小，则表明判定方法可能存在较大偏差，需要重新设计或改进。
Kappa 指标通过量化一致性程度，帮助我们评估和改进判定方法的可靠性和有效性。



## 大型搜索引擎的评价
### 评价指标
1. Top K 的正确率
- 由于 Web 下召回率难以计算，搜索引擎常使用 Top K 的正确率来度量，例如 K=10。Top K 的正确率关注返回结果中前 K 个文档的正确性，即这些文档与用户查询的相关性。

2. 考虑返回结果位置的指标
- 搜索引擎还使用考虑返回结果位置的指标，例如正确答案在第一个返回会比第十个返回的系统给予更大的指标。这种指标通过赋予不同位置的返回结果不同的权重，来衡量系统的性能。例如，可以使用加权正确率，其中第一个返回结果的权重最高，后续结果的权重逐渐降低。

3. 非相关度指标
- 搜索引擎也使用非相关度指标，例如第一个结果的点击率。该指标衡量用户对第一个返回结果的点击频率，反映了用户对搜索结果的满意度。然而，仅仅基于单个点击的指标不太可靠，因为用户可能被检索结果的摘要所误导，点击后发现实际上是不相关的。

4. A/B 测试
- A/B 测试是大型搜索引擎常用的一种评价方法。其目标是测试某个独立的创新点。先决条件是大型搜索引擎已经在上线运行，很多用户使用老系统。将一小部分（如 1%）流量导向包含创新点的新系统，对新旧系统进行自动评价，并得到某个评价指标，例如第一个结果的点击率。通过新旧系统的指标对比，可以判断创新点的效果。A/B 测试是大型搜索引擎最信赖的方法之一。
### 相关性的定义
1. 独立的查询-文档对
- 上述相关性定义是针对独立的查询-文档对，即每个查询和文档之间的相关性是独立评估的。

2. 边缘相关性
- 另一种定义是边缘相关性（Marginal Relevance），它指的是结果列表中位置 k 上的文档相对于其前面的文档 d1​,…,dk−1​ 中包含的信息之外所带来的额外信息。同一篇文档，后面再次出现不能带来更多的信息。边缘相关性考虑了结果列表中文档的顺序和信息的增量，有助于评估结果列表的整体质量。。